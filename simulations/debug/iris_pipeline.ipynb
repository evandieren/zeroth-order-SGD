{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('../src/')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data_train = pd.read_csv('../data/iris_train.csv')\n",
    "\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string target values to numeric values\n",
    "#       class 0: Iris-setosa\n",
    "#       class 1: Iris-versicolor\n",
    "#       class 2: Iris-virginica\n",
    "data_train['species'] = data_train['species'].map({'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2})\n",
    "\n",
    "# also convert all string numeric values to float ['2' -> 2.0]\n",
    "data_train = data_train.apply(pd.to_numeric)\n",
    "\n",
    "# extract frequency of each species class\n",
    "class_freq = data_train['species'].value_counts()\n",
    "class_freq = list(class_freq.sort_index())\n",
    "\n",
    "# Visual data\n",
    "graph = plt.bar(list(range(0,3)), class_freq)\n",
    "plt.xticks(list(range(0,3)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Species')\n",
    "plt.title('Training Data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for training\n",
    "\n",
    "# Convert pandas dataframe to array\n",
    "data_train_array = data_train.values\n",
    "\n",
    "# Split x (features) and y (targets)\n",
    "x_array = data_train_array[:, :4]\n",
    "y_array = data_train_array[:, 4]\n",
    "\n",
    "# Tensorify\n",
    "X = torch.tensor(x_array, dtype=torch.float)\n",
    "Y = torch.tensor(y_array, dtype=torch.long)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture (MLP, 1 hidden layer): layer sizes\n",
    "# Note: will stick to 1 hidden layer for iris, will set up nb of hidden layers as hyperparam for larger dataset\n",
    "INPUT_NEURONS = 4\n",
    "hidden_neurons_range = [10] # hidden layer 1\n",
    "OUTPUT_NEURONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecutre: activation functions\n",
    "\n",
    "# Normal network with sigmoid\n",
    "def create_standard_sigmoid_network(hidden_neurons):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(INPUT_NEURONS, hidden_neurons),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(hidden_neurons, OUTPUT_NEURONS)\n",
    "    )\n",
    "\n",
    "# Normal network with relu\n",
    "def create_standard_relu_network(hidden_neurons):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(INPUT_NEURONS, hidden_neurons),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_neurons, OUTPUT_NEURONS)\n",
    "    )\n",
    "\n",
    "network_funs = [\n",
    "    (\"standard_sigmoid\", create_standard_sigmoid_network),\n",
    "    (\"standard_relu\", create_standard_relu_network),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "# Training constants\n",
    "lr_range = [rate for rate in np.logspace(-4,-1,num=5,base=10.0)]\n",
    "NUM_EPOCH = 500\n",
    "\n",
    "# Loss function -> could be hyperparam too\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train each network and plot the loss\n",
    "for name, network_fun in network_funs:\n",
    "    for hidden_neurons in hidden_neurons_range:\n",
    "        for lr in lr_range:\n",
    "            print(f\"Network: {name}, HIDDEN_NEURONS: {hidden_neurons}, LR: {lr} \\n=========\")\n",
    "\n",
    "            # Create new instance of network\n",
    "            network = network_fun(hidden_neurons)\n",
    "\n",
    "            # Optimiser\n",
    "            optimiser = torch.optim.SGD(network.parameters(), lr=lr)\n",
    "\n",
    "            # store all losses for visualisation\n",
    "            all_losses = []\n",
    "\n",
    "            # train a neural network\n",
    "            for epoch in range(NUM_EPOCH):\n",
    "                # Perform forward pass\n",
    "                Y_pred = network(X)\n",
    "                # Compute loss\n",
    "                loss = loss_func(Y_pred, Y)\n",
    "                all_losses.append(loss.item())\n",
    "\n",
    "                # print progress\n",
    "                if epoch % 50 == 0:\n",
    "                    # convert three-column predicted Y values to one column for comparison\n",
    "                    _, predicted = torch.max(torch.nn.functional.softmax(Y_pred,1), 1)\n",
    "                    # calculate and print accuracy\n",
    "                    total = predicted.size(0)\n",
    "                    correct = predicted.data.numpy() == Y.data.numpy()\n",
    "                    # Print\n",
    "                    print('Epoch [%d / %d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "                        % (epoch + 1, NUM_EPOCH, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "                # Clear the gradients before running the backward pass.\n",
    "                network.zero_grad()\n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "                # Step optimiser\n",
    "                optimiser.step()\n",
    "\n",
    "            # Plot\n",
    "            plt.figure()\n",
    "            plt.plot(all_losses)\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

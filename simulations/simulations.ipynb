{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Learning: Project Simulations\n",
    "\n",
    "Author: Pascal Dreieck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "\n",
    "from optimisation_algorithms import logistic_f, logistic_df, GDClassifer, SGDClassifer, SVRGClassifer, SVRGClassifer_Alt, SAGAClassifer\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "N_SAMPLES = 50\n",
    "DIMENSIONS = [10,10,10]\n",
    "\n",
    "DATASETS = []\n",
    "for i, dim in enumerate(DIMENSIONS):\n",
    "    cluster_1 = np.random.multivariate_normal(\n",
    "        mean=[1] * dim,\n",
    "        cov=np.diag([2] * dim),\n",
    "        size=N_SAMPLES * dim\n",
    "        )\n",
    "    cluster_2 = np.random.multivariate_normal(\n",
    "        mean=[-1] * dim,\n",
    "        cov=np.diag([2 * np.sqrt(10)] * dim),\n",
    "        size=N_SAMPLES * dim\n",
    "        )\n",
    "    Xn = np.concatenate((cluster_1, cluster_2), axis=0)\n",
    "\n",
    "    Yn = np.ones((N_SAMPLES * dim * 2,))\n",
    "    Yn[:N_SAMPLES * dim] = -1\n",
    "\n",
    "    DATASETS.append((Xn, Yn))\n",
    "\n",
    "# Redo X2 to vary covariance\n",
    "cluster_1 = np.random.multivariate_normal(\n",
    "    mean=[1] * DIMENSIONS[-1],\n",
    "    cov=np.diag(([4] * (DIMENSIONS[-1] // 2)) + ([1] * (DIMENSIONS[-1] - (DIMENSIONS[-1] // 2 )))),\n",
    "    size=N_SAMPLES * DIMENSIONS[-1]\n",
    "    )\n",
    "cluster_2 = np.random.multivariate_normal(\n",
    "    mean=[-1] * DIMENSIONS[-1],\n",
    "    cov=np.diag(([1] * (DIMENSIONS[-1] // 2)) + ([4] * (DIMENSIONS[-1] - (DIMENSIONS[-1] // 2 )))),\n",
    "    size=N_SAMPLES * DIMENSIONS[-1]\n",
    "    )\n",
    "new_X2 = np.concatenate((cluster_1, cluster_2), axis=0)\n",
    "\n",
    "(old_X2, Y2) = DATASETS[-1]\n",
    "DATASETS[-1] = (new_X2, Y2)\n",
    "\n",
    "# Center at (0,0)\n",
    "for Xn, Yn in DATASETS:\n",
    "    Xn[:, 0] = Xn[:, 0] - Xn[:, 0].mean()\n",
    "    Xn[:, 1] = Xn[:, 1] - Xn[:, 1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST VALUES\n",
    "ETAS = (5e-1, 1e-1, 5e-2, 1e-2)\n",
    "MAX_ITER  = 200 # 1000\n",
    "MAX_GRADS = 10000\n",
    "w_0s = []\n",
    "for dim in DIMENSIONS:\n",
    "    temp = np.array([0] * dim)\n",
    "    w_0s.append(temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun tests or read from file\n",
    "RERUN_TESTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RERUN_TESTS:\n",
    "    # Setup dictionaries\n",
    "    step_size_complexity_dict = {}\n",
    "\n",
    "    # Run over all datasets\n",
    "    for j, tup in enumerate(DATASETS):\n",
    "        print(f\"Dataset {j+1} / {len(DATASETS)}\")\n",
    "        Xn, Yn = tup\n",
    "        M = len(Xn) // 2\n",
    "\n",
    "        for i, eta in enumerate(ETAS):\n",
    "            print(f\"Eta {i+1} / {len(ETAS)}\")\n",
    "            \n",
    "            print(\"gd...\", end=\"\")\n",
    "            step_size_complexity_dict[(j, i, 'gd')] = GDClassifer(logistic_f, logistic_df, Xn, Yn, w_0s[j],\n",
    "                eta=eta, stopping_times=(None,MAX_GRADS), random_state=RANDOM_STATE)\n",
    "            print(\"sgd...\", end=\"\")\n",
    "            step_size_complexity_dict[(j, i, 'sgd')] = SGDClassifer(logistic_f, logistic_df, Xn, Yn, w_0s[j],\n",
    "                eta=eta, stopping_times=(None,MAX_GRADS), random_state=RANDOM_STATE)\n",
    "            print(\"saga...\", end=\"\")\n",
    "            step_size_complexity_dict[(j, i, 'saga')] = SAGAClassifer(logistic_f, logistic_df, Xn, Yn, w_0s[j],\n",
    "                eta=eta, stopping_times=(None,MAX_GRADS), random_state=RANDOM_STATE)\n",
    "            print(\"svrg...\", end=\"\")\n",
    "            step_size_complexity_dict[(j, i, 'svrg')] = SVRGClassifer(logistic_f, logistic_df, Xn, Yn, w_0s[j],\n",
    "                eta=eta, m=M, stopping_times=(None,MAX_GRADS), random_state=RANDOM_STATE)\n",
    "            # print(\"svrg_alt...\", end=\"\")\n",
    "            # step_size_complexity_dict[(j, i, 'svrg_alt')] = SVRGClassifer_Alt(logistic_f, logistic_df, Xn, Yn, w_0s[j],\n",
    "            #     eta=eta, m=M, stopping_times=(None,MAX_GRADS), random_state=RANDOM_STATE)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RERUN_TESTS:\n",
    "    # Save data\n",
    "    with open('data/step_size_complexity_dict.pk','wb') as f:\n",
    "        pk.dump(step_size_complexity_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RERUN_TESTS:\n",
    "    # Read values\n",
    "    with open('data/step_size_complexity_dict.pk','rb') as f:\n",
    "        data = f.read()\n",
    "        step_size_complexity_dict = pk.loads(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "colours = [\"black\", \"red\", \"violet\", \"darkblue\", 'green']\n",
    "linestyles = ['solid', 'dashdot', 'dashed', 'dotted']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step-Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plot\n",
    "fig = plt.figure(figsize=(10, 8), constrained_layout=True)\n",
    "fig.suptitle(f\"Convergence of Optimisation Algorithms\", fontsize=20, x=0.5, y=1.05)\n",
    "\n",
    "subfigs = fig.subfigures(nrows=len(ETAS[:-1]), ncols=1)\n",
    "\n",
    "for i, eta in enumerate(ETAS[:-1]):\n",
    "    subfigs[i].suptitle(f\"$\\eta$ = {eta}\", fontsize=15, x=-0.015, y=0.65, rotation=90)\n",
    "\n",
    "    # Run over all datasets\n",
    "    for j, _ in enumerate(DATASETS):\n",
    "\n",
    "        # Complexity Subplot\n",
    "        ax = subfigs[i].add_subplot(1, len(DATASETS), j + 1)\n",
    "\n",
    "        _, gd_loss, _, gd_grad_count = step_size_complexity_dict[(j, i, 'gd')]\n",
    "        _, sgd_loss, _, sgd_grad_count = step_size_complexity_dict[(j, i, 'sgd')]\n",
    "        _, svrg_loss, _, svrg_grad_count = step_size_complexity_dict[(j, i, 'svrg')]\n",
    "        # _, svrg_alt_loss, _, svrg_alt_grad_count = step_size_complexity_dict[(j, i, 'svrg_alt')]\n",
    "        _, saga_loss, _, saga_grad_count = step_size_complexity_dict[(j, i, 'saga')]\n",
    "\n",
    "        def helper(grad_count, loss, max_grads):\n",
    "            grad_output = []\n",
    "            for grad in grad_count:\n",
    "                if grad > max_grads:\n",
    "                    break\n",
    "                else:\n",
    "                    grad_output.append(grad)\n",
    "            loss_output = loss[:len(grad_output)]\n",
    "\n",
    "            return grad_output, loss_output\n",
    "        \n",
    "        DIV = 1\n",
    "        ax.plot(*helper(gd_grad_count, gd_loss, MAX_GRADS//DIV),\n",
    "            label=f\"gd\" if i == 0 and j == 0 else None,\n",
    "            c=colours[0], linestyle=linestyles[0], linewidth=2.0)\n",
    "        ax.plot(*helper(sgd_grad_count, sgd_loss, MAX_GRADS//DIV),\n",
    "            label=f\"sgd\" if i == 0 and j == 0 else None,\n",
    "            c=colours[1], linestyle=linestyles[0], linewidth=2.0)\n",
    "        ax.plot(*helper(svrg_grad_count, svrg_loss, MAX_GRADS//DIV),\n",
    "            label=f\"svrg\" if i == 0 and j == 0 else None,\n",
    "            c=colours[3], linestyle=linestyles[0], linewidth=2.0)\n",
    "        # ax.plot(svrg_alt_grad_count, svrg_alt_loss,\n",
    "        #     label=f\"svrg_alt: eta = {eta}\" if j == 0 else None,\n",
    "        #     c=colours[4], linestyle=linestyles[0], linewidth=2.5)\n",
    "        ax.plot(*helper(saga_grad_count, saga_loss, MAX_GRADS//DIV),\n",
    "            label=f\"saga\" if i == 0 and j == 0 else None,\n",
    "            c=colours[4], linestyle=linestyles[0], linewidth=2.0)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"Dataset {j}\", fontsize=15)\n",
    "        ax.set_xlabel(\"Gradients Computed\", weight='bold', fontsize=10)\n",
    "        ax.set_ylabel(\"Training Loss\", weight='bold', fontsize=10)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.tick_params(which='major', size=10)\n",
    "        ax.tick_params(which='minor', size=7)\n",
    "        ax.tick_params(which='minor', )\n",
    "\n",
    "# Format and Save Plot\n",
    "fig.legend(loc=\"lower center\", fontsize=15, bbox_to_anchor=(0.5, -0.075), labelspacing=1.0, ncols = 4)\n",
    "fig.savefig(f\"plots/total_plot.png\", bbox_inches='tight')\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2c0e908debce768337a8eca8a0d3db6453898581511807fc44daf361bb700d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeroth Pipeline\n",
    "\n",
    "This pipeline compares zeroth order GD against standard GD. Three different zeroth order approximations --- one difference, two difference, and coordinate --- are tested."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('../src/')\n",
    "if p not in sys.path:\n",
    "    sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from difference_methods import one_point_estimate, two_point_estimate, coordinate_estimate\n",
    "from linear_zeroth_function import Linear_Zeroth\n",
    "from sigmoid_zeroth_function import Sigmoid_Zeroth\n",
    "from relu_zeroth_function import ReLU_Zeroth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data_train = pd.read_csv('../data/pendigits.csv')\n",
    "\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract frequency of each class\n",
    "class_freq = data_train['class'].value_counts()\n",
    "class_freq = list(class_freq.sort_index())\n",
    "\n",
    "nb_classes = len(class_freq)\n",
    "nb_features = data_train.shape[1]-1\n",
    "\n",
    "# Visual data\n",
    "graph = plt.bar(list(range(nb_classes)), class_freq)\n",
    "plt.xticks(list(range(nb_classes)))\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.title('Full data')\n",
    "\n",
    "plt.show() # balanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data for training\n",
    "\n",
    "# Convert pandas dataframe to array\n",
    "data_train_array = data_train.values\n",
    "\n",
    "# Split x (features) and y (targets)\n",
    "x_array = data_train_array[:, :nb_features]\n",
    "y_array = data_train_array[:, nb_features]\n",
    "\n",
    "# Tensorify\n",
    "X = torch.tensor(x_array, dtype=torch.float)\n",
    "Y = torch.tensor(y_array, dtype=torch.long)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT/OUTPUT layer sizes\n",
    "INPUT_NEURONS = nb_features\n",
    "OUTPUT_NEURONS = nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_neurons_range = list(range(min(INPUT_NEURONS, OUTPUT_NEURONS), max(INPUT_NEURONS, OUTPUT_NEURONS)+1, 2))\n",
    "mu_range = [1e-3, 1e-2, 1e-1]\n",
    "n_range = list(range(1, min(INPUT_NEURONS, OUTPUT_NEURONS), 4))\n",
    "difference_method_range = ['one','two','coord','sgd']\n",
    "\n",
    "# Display hyperparameters:\n",
    "print(f\"Hidden Neuron Range: {hidden_neurons_range}\")\n",
    "print(f\"Mu Range: {mu_range}\")\n",
    "print(f\"N Range: {n_range}\")\n",
    "print(f\"Descent Methods: {difference_method_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architectures: 1 hidden layer\n",
    "\n",
    "# Activation functions\n",
    "# Normal network with sigmoid\n",
    "def create_standard_sigmoid_network(hidden_neurons, mu, n, difference_method):\n",
    "    torch.manual_seed(1) # so that same network init with same weights at each creation\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(INPUT_NEURONS, hidden_neurons),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(hidden_neurons, OUTPUT_NEURONS)\n",
    "    )\n",
    "\n",
    "# Full Zeroth Order sigmoid\n",
    "def create_zeroth_sigmoid_network(hidden_neurons, mu, n, difference_method):\n",
    "    torch.manual_seed(1) # so that same network init with same weights at each creation\n",
    "    return torch.nn.Sequential(\n",
    "        Linear_Zeroth(INPUT_NEURONS, hidden_neurons, bias=False, difference_method=difference_method, mu=mu, n=n),\n",
    "        Sigmoid_Zeroth(difference_method=difference_method, mu=mu, n=n),\n",
    "        Linear_Zeroth(hidden_neurons, OUTPUT_NEURONS, bias=False, difference_method=difference_method, mu=mu, n=n)\n",
    ")\n",
    "\n",
    "# Normal network with relu\n",
    "def create_standard_relu_network(hidden_neurons, mu, n, difference_method):\n",
    "    torch.manual_seed(1) # so that same network init with same weights at each creation\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(INPUT_NEURONS, hidden_neurons),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_neurons, OUTPUT_NEURONS)\n",
    "    )\n",
    "\n",
    "# Full Zeroth Order relu\n",
    "def create_zeroth_relu_network(hidden_neurons, mu, n, difference_method):\n",
    "    torch.manual_seed(1) # so that same network init with same weights at each creation\n",
    "    return torch.nn.Sequential(\n",
    "        Linear_Zeroth(INPUT_NEURONS, hidden_neurons, bias=False, difference_method=difference_method, mu=mu, n=n),\n",
    "        ReLU_Zeroth(difference_method=difference_method, mu=mu, n=n),\n",
    "        Linear_Zeroth(hidden_neurons, OUTPUT_NEURONS, bias=False, difference_method=difference_method, mu=mu, n=n),\n",
    ")\n",
    "\n",
    "std_network_funs = [\n",
    "    (\"standard_sigmoid\", create_standard_sigmoid_network),\n",
    "    (\"standard_relu\", create_standard_relu_network),\n",
    "]\n",
    "\n",
    "zero_network_funs = [\n",
    "    (\"zeroth_sigmoid\", create_zeroth_sigmoid_network),\n",
    "    (\"zeroth_relu\", create_zeroth_relu_network),\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "# Training constants\n",
    "LR = 0.01\n",
    "NUM_EPOCH = 500\n",
    "\n",
    "# Loss function\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot or save? False => Save\n",
    "plot = False\n",
    "path = \"plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train each network and plot the loss:\n",
    "for net_idx, network in enumerate(zero_network_funs):\n",
    "    name, network_fun = network\n",
    "    for hidden_neurons in hidden_neurons_range:\n",
    "        for mu in mu_range:\n",
    "            for n in n_range:\n",
    "                plt.figure()\n",
    "                for diff_method in difference_method_range:\n",
    "                    print(f\"Network: {name}, Hidden neurons: {hidden_neurons}, Mu: {mu}, N: {n} \\n=========\")\n",
    "\n",
    "                    # Create new instance of network\n",
    "                    if diff_method == \"sgd\":\n",
    "                        network_fun = std_network_funs[net_idx][1]\n",
    "                    network = network_fun(hidden_neurons, mu, n, diff_method)\n",
    "\n",
    "                    # Optimiser\n",
    "                    optimiser = torch.optim.SGD(network.parameters(), lr=LR)\n",
    "\n",
    "                    # store all losses for visualisation\n",
    "                    all_losses = []\n",
    "\n",
    "                    # train a neural network\n",
    "                    for epoch in tqdm.tqdm(range(NUM_EPOCH)):\n",
    "                        # Perform forward pass\n",
    "                        Y_pred = network(X)\n",
    "                        # Compute loss\n",
    "                        loss = loss_func(Y_pred, Y)\n",
    "                        all_losses.append(loss.item())\n",
    "\n",
    "                        # print progress\n",
    "                        if epoch % 50 == 0:\n",
    "                            # convert three-column predicted Y values to one column for comparison\n",
    "                            _, predicted = torch.max(torch.nn.functional.softmax(Y_pred,1), 1)\n",
    "                            # calculate and print accuracy\n",
    "                            total = predicted.size(0)\n",
    "                            correct = predicted.data.numpy() == Y.data.numpy()\n",
    "                            # Print\n",
    "                            # print('Epoch [%d / %d] Loss: %.4f  Accuracy: %.2f %%' % (epoch + 1, NUM_EPOCH, loss.item(), 100 * sum(correct)/total))\n",
    "\n",
    "                        # Clear the gradients before running the backward pass.\n",
    "                        network.zero_grad()\n",
    "                        # Perform backward pass\n",
    "                        loss.backward()\n",
    "                        # Step optimiser\n",
    "                        optimiser.step()\n",
    "\n",
    "                    # Plot\n",
    "                    plt.plot(all_losses)\n",
    "                    \n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend([\"One\", \"Two\", \"Coord\", \"SGD\"])\n",
    "                if plot:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.savefig(f\"{path}{name}_hn{hidden_neurons}_mu{mu}_n{n}.png\")\n",
    "                    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
